{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_train_1.5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTp70qN146IzKcBKqh/g99"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"J7uL2MuLx_MO","colab_type":"text"},"source":["The setup:\n","\n","tensorflow is also imported to be able to utilize its dataset processing functionalities\n"]},{"cell_type":"code","metadata":{"id":"ySKTTRyZbkSl","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A9XnQ5lh2PD5","colab_type":"text"},"source":["It is also necessary to create a folder to store the results and another one to store the training process"]},{"cell_type":"code","metadata":{"id":"Zs170gvl2DWC","colab_type":"code","colab":{}},"source":["!mkdir generated_training_images\n","!mkdir generated_final_images"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5suntVByX_K","colab_type":"text"},"source":["Dataset preparation:\n","\n","There is not a lot of things to do with the dataset, just load it from the library and put together both the training and testing sets since we just want as much data as posible to train the generator"]},{"cell_type":"code","metadata":{"id":"F7RoR2F-brjX","colab_type":"code","colab":{}},"source":["batch_size = 64\n","# The idea is just to get lots of data to train\n","# the generator, so labels are not needed\n","(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","# Data is in ints from 0 to 255\n","all_digits = all_digits.astype(\"float32\") / 255\n","# -1 makes it copy the value from the source array\n","# the last 1 is the number of channels\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n","# batch divides in batches\n","# prefetch makes later 32 elements be prepared while processing the current one,\n","# improving latency and throughput but using extra memory\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hnviGrltytN_","colab_type":"text"},"source":["This is the discriminator model, the one in charge of deciding wether the data it is presented to it is coming from the generator or from the original dataset\n"]},{"cell_type":"code","metadata":{"id":"5S_omWObfvVe","colab_type":"code","outputId":"6ec00849-3246-4ea4-f5af-8692085fa82e","executionInfo":{"status":"ok","timestamp":1590609220977,"user_tz":300,"elapsed":326,"user":{"displayName":"Eduardo Cuesta Córdova","photoUrl":"","userId":"11072312511090675042"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["discriminator = keras.Sequential(\n","    [\n","     keras.Input(shape=(28, 28, 1)),\n","     # 64 filters on 3x3 kernels, same convolution and 2 pad to go\n","     # to 14 x 14\n","     layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","     # DCGANS first layer of discriminator is not batch normalized\n","     # so that it can learn the statistic qualities of the data\n","     # leaky relu better for training, alpha is the negative slope coeff\n","     layers.LeakyReLU(alpha=0.2),\n","     # Normally depth ramps up\n","     layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","     layers.BatchNormalization(),\n","     layers.LeakyReLU(alpha=0.2),\n","     # Gets the max on the whole 7x7 tensor in each of the 64 channels\n","     # returns size of samples, channels\n","     # DCGAN paper says having this over fully connected layer improves \n","     # model stability, but hurts convergence speed\n","     # As this is a small model, we have no problem with speed\n","     # Middle ground is flatten and then feed into sigmoid\n","     # Dense default activation is linear\n","     layers.GlobalMaxPooling2D(),\n","     layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","discriminator.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 14, 14, 64)        640       \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","global_max_pooling2d_2 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 75,137\n","Trainable params: 74,881\n","Non-trainable params: 256\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GFlYz_JVzO3X","colab_type":"text"},"source":["This is the generator model, the one in charge of generating images that look like those in the dataset\n"]},{"cell_type":"code","metadata":{"id":"J-QSU0Ka5QmP","colab_type":"code","outputId":"e8d6860c-2378-4475-b8fc-5b3e7d91ae65","executionInfo":{"status":"ok","timestamp":1590609094176,"user_tz":300,"elapsed":657,"user":{"displayName":"Eduardo Cuesta Córdova","photoUrl":"","userId":"11072312511090675042"}},"colab":{"base_uri":"https://localhost:8080/","height":454}},"source":["# The dimension of the latent space, like the feature space of convnets\n","latent_dim = 128\n","\n","generator = keras.Sequential(\n","    [\n","     # From latent space\n","     keras.Input(shape=(latent_dim,)),\n","     # No dense in DCGAN paper\n","     layers.Dense(7 * 7 * 128),\n","     layers.Reshape((7, 7, 128)),\n","     # Via a transposed convolution, to image\n","     layers.Conv2DTranspose(128, (4, 4), strides=(2,2), padding=\"same\"),\n","     layers.BatchNormalization(),\n","     layers.LeakyReLU(alpha=0.2),\n","     layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","     layers.BatchNormalization(),\n","     layers.LeakyReLU(alpha=0.2),\n","     # No batchnorm here\n","     # DCGAN paper said tanh, initially sigmoid\n","     layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"tanh\"),\n","    ],\n","    name=\"generator\",\n",")\n","\n","generator.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_2 (Dense)              (None, 6272)              809088    \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 28, 28, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 28, 28, 1)         6273      \n","=================================================================\n","Total params: 1,340,929\n","Trainable params: 1,340,417\n","Non-trainable params: 512\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_rKIR11jz_J6","colab_type":"text"},"source":["This class overrides the methods compile and train_step from the keras model class.\n","\n","compile is overridden to get the optimizers and loss from the user.\n","\n","train_step is overriden to use the GAN training algorithm with k (discriminator training steps per generator training step) = 1.\n"]},{"cell_type":"code","metadata":{"id":"HuyOr_Dq_pWF","colab_type":"code","colab":{}},"source":["class GAN(keras.Model):\n","  def __init__(self, discriminator, generator, latent_dim):\n","    # For python inheritance\n","    super(GAN, self).__init__()\n","    self.discriminator = discriminator\n","    self.generator = generator\n","    # Latent space inheritance\n","    self.latent_dim = latent_dim\n","\n","  # Override this to use own signature for receiving two optimizers\n","  def compile(self, d_optimizer, g_optimizer, loss_fn):\n","    super(GAN, self).compile()\n","    # Compiles the model and then just adds the optimizers and loss\n","    self.d_optimizer = d_optimizer\n","    self.g_optimizer = g_optimizer\n","    self.loss_fn = loss_fn\n","\n","  # For custom learning algorithm, train_step(self, data)\n","  def train_step(self, real_images):\n","    # ADD BATCH NORM??? CHECK SALIMANS\n","    # CHECK REGULARIZATION\n","\n","    # If calling fit(x, y...), data will be tuple(x, y)\n","    # and we don't want labels\n","    # When calling from dataset it will be whatever dataset yields\n","    # per batch\n","    if isinstance(real_images, tuple):\n","      # Just want the x from (x, y)\n","      real_images = real_images[0]\n","    batch_size = tf.shape(real_images)[0]\n","    # Better to sample from gaussian than uniform\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","    generated_images = self.generator(random_latent_vectors)\n","    # Make a single dataset with both fake and real images\n","    combined_images = tf.concat([generated_images, real_images], axis=0)\n","    # Make the labels part by concatting horizontally (ax0) batch_size 1s and 0s\n","    labels = tf.concat(\n","        [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n","    )\n","    # Add random noise to labels\n","    # Salimans 2016 says that it should be one sided and replacing\n","    # 1 or 0 with a or b\n","    # tf.random.uniform [0, 1)\n","    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","\n","    # Train the discriminator\n","\n","    # This records the operations to automatically differentiate the \n","    # variables inside the context\n","    with tf.GradientTape() as tape:\n","      predictions = self.discriminator(combined_images)\n","      d_loss = self.loss_fn(labels, predictions)\n","    # Derivative of loss with respect to the weights \n","    # CHECK THIS\n","    gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","    # zip gives you an iterator of tuples made out of the passed iterators\n","    self.d_optimizer.apply_gradients(\n","        zip(gradients, self.discriminator.trainable_weights)\n","    )\n","\n","    # Create new random vectors\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","    made_real_labels = tf.zeros((batch_size, 1))\n","\n","    # Train the generator\n","    with tf.GradientTape() as tape:\n","      predictions = self.discriminator(self.generator(random_latent_vectors))\n","      # This tells how many real images\n","      g_loss = self.loss_fn(made_real_labels, predictions)\n","    gradients = tape.gradient(g_loss, self.generator.trainable_weights)\n","    self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_weights))\n","    return {\"d_loss\": d_loss, \"g_loss\": g_loss}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ncc3TOJr0tZg","colab_type":"text"},"source":["**For this to work there has to be a folder named generated_training_images**\n","\n","This is just a keras callback that runs the function on_epoch_end whenever the model finishes an epoch. In this case this is used to save three images to see the model progress during training."]},{"cell_type":"code","metadata":{"id":"VgF1AFadA53Y","colab_type":"code","colab":{}},"source":["class GANMonitor(keras.callbacks.Callback):\n","  def __init__(self, num_img=3, latent_dim=128):\n","    self.num_img = num_img\n","    self.latent_dim = latent_dim\n","\n","  def on_epoch_end(self, epoch, logs=None):\n","    random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","    generated_images = self.model.generator(random_latent_vectors)\n","    generated_images *= 255\n","    generated_images.numpy()\n","    for i in range(self.num_img):\n","      img = keras.preprocessing.image.array_to_img(generated_images[i])\n","      img.save(\"./generated_training_images/generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yn8-kMzU1F7b","colab_type":"text"},"source":["This is the model instantiation, compilation and training.\n","30 epochs produces fine results, altough 100 were used for generating the images of the report."]},{"cell_type":"code","metadata":{"id":"sJ0RWIO2v0Pq","colab_type":"code","outputId":"c9cde8ad-653d-4ecf-ba4a-b550f970f77a","executionInfo":{"status":"error","timestamp":1590609371987,"user_tz":300,"elapsed":144057,"user":{"displayName":"Eduardo Cuesta Córdova","photoUrl":"","userId":"11072312511090675042"}},"colab":{"base_uri":"https://localhost:8080/","height":622}},"source":["epochs = 30\n","\n","gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    # The vector of predictions will be binary\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",")\n","gan.fit(\n","    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.6262 - g_loss: 0.8900\n","Epoch 2/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.5788 - g_loss: 0.9909\n","Epoch 3/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.4119 - g_loss: 1.4199\n","Epoch 4/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.3091 - g_loss: 1.8309\n","Epoch 5/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.2513 - g_loss: 2.1757\n","Epoch 6/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.2189 - g_loss: 2.4102\n","Epoch 7/30\n","1094/1094 [==============================] - 20s 18ms/step - d_loss: 0.1944 - g_loss: 2.6383\n","Epoch 8/30\n"," 199/1094 [====>.........................] - ETA: 15s - d_loss: 0.1754 - g_loss: 2.7475"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-2538977a7979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m gan.fit(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"giLwEa0M1fDh","colab_type":"text"},"source":["You might want to save the model results or configuration in drive."]},{"cell_type":"code","metadata":{"id":"dJsisp8E2PBi","colab_type":"code","outputId":"5f4dc253-477e-495c-e0e8-1c497e3aeeeb","executionInfo":{"status":"ok","timestamp":1590527911952,"user_tz":300,"elapsed":23661,"user":{"displayName":"Eduardo Cuesta Córdova","photoUrl":"","userId":"11072312511090675042"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YNXhfKBn1mcJ","colab_type":"text"},"source":["**For this to work there has to be a folder named generated_final_images**\n","\n","This is for saving the model and generating result images"]},{"cell_type":"code","metadata":{"id":"rvK078OkBiTs","colab_type":"code","outputId":"9614da61-d4cd-4e65-bd47-dc35e1611b97","executionInfo":{"status":"ok","timestamp":1590527093972,"user_tz":300,"elapsed":2957,"user":{"displayName":"Eduardo Cuesta Córdova","photoUrl":"","userId":"11072312511090675042"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["generator.save('gen2')\n","generator2 = keras.models.load_model('gen2')\n","num_images = 10\n","random_latent_vectors = tf.random.normal(shape=(num_images, 128))\n","generated_images = generator2(random_latent_vectors)\n","for i in range(0, num_images):\n","  img = keras.preprocessing.image.array_to_img(generated_images[i])\n","  img.save(\"./generated_final_images/generated_img_{i}.png\".format(i=i))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Assets written to: gen2/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]}]}